{
 "metadata": {
  "name": "",
  "signature": "sha256:28f18dedc61b0b1c4c1f8e319c0c01e8989a6b3fdf4994414f00fd6a7138c158"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "import pandas as pd\n",
      "import time\n",
      "import csv\n",
      "import numpy as np\n",
      "import datetime\n",
      "import re\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "\n",
      "def read_data():\n",
      "    \"\"\" Read and pre-process data\n",
      "        >>> videos_matrix = read_data()\n",
      "        >>> videos_matrix[:3]\n",
      "          video_id_left container_id_left origin_country_left origin_language_left  \\\n",
      "        0         TV001      Container001                  us                   en\n",
      "        1         TV001      Container001                  us                   en\n",
      "        2         TV001      Container001                  us                   en\n",
      "\n",
      "          adult_left broadcast_from_left broadcast_to_left season_number_left  \\\n",
      "        0      False                None              None               None\n",
      "        1      False                None              None               None\n",
      "        2      False                None              None               None\n",
      "\n",
      "          content_owner_id_left genres_left  \\\n",
      "        0        ContentOwner01        None\n",
      "        1        ContentOwner01        None\n",
      "        2        ContentOwner01        None\n",
      "\n",
      "                                 ...                          origin_language_right  \\\n",
      "        0                        ...                                             en\n",
      "        1                        ...                                             en\n",
      "        2                        ...                                             zt\n",
      "\n",
      "          adult_right broadcast_from_right broadcast_to_right season_number_right  \\\n",
      "        0       False                 None               None                None\n",
      "        1       False              2013-06            2013-08                   3\n",
      "        2       False              2012-07            2012-11                None\n",
      "\n",
      "          content_owner_id_right                                       genres_right  \\\n",
      "        0         ContentOwner01                                               None\n",
      "        1         ContentOwner02                            Action & Adventure (1g)\n",
      "        2         ContentOwner03  Comedy (6g), Drama (9g), Idol Drama (1038g), R...\n",
      "\n",
      "          episode_count_right                                    person_id_right  \\\n",
      "        0                   5                                                NaN\n",
      "        1                  10                                                NaN\n",
      "        2                  77  Cast0898 Cast0483 Cast1344 Cast1688 Cast0503 C...\n",
      "\n",
      "                                               user_id_right\n",
      "        0  189500_2 328741_2 579541_2 153183_2 151295_3 3...\n",
      "        1                                           353674_3\n",
      "        2  759744_1 379687_3 160301_1 159490_1 151124_1 1...\n",
      "    \"\"\"\n",
      "    videos = pd.read_csv('./data/20150701094451-Video_attributes.csv')\n",
      "    casts = pd.read_csv('./data/20150701094451-Video_casts.csv')\n",
      "    behaviors = pd.read_csv('./data/20150701094451-Behavior_training.csv',dtype={'user_id':pd.np.string_,'score':pd.np.string_})\n",
      "    # we don't care about these for now\n",
      "    behaviors = behaviors.drop(['date_hour','mv_ratio'], 1)\n",
      "    # flattening casts\n",
      "    casts = casts.drop(['country','gender'], 1).groupby('container_id',as_index=False).agg(lambda x: ' '.join(x.person_id))\n",
      "    videos = pd.merge(videos, casts, on=['container_id'], how='left', suffixes=['_left', '_right'])\n",
      "    # combined ppl who watched this video (and their \"scores\")\n",
      "    behaviors = behaviors.groupby('video_id',as_index=False).agg(lambda x: ' '.join(x.user_id + '_' + x.score)).drop('score', 1)\n",
      "    videos = pd.merge(videos, behaviors, on=['video_id'], how='left', suffixes=['_left', '_right'])\n",
      "    # Constructing videos_matrix\n",
      "    videos['dummy'] = 1\n",
      "    videos_matrix = pd.merge(videos, videos, on=['dummy'], suffixes=['_left', '_right'])\n",
      "    videos_matrix = videos_matrix.drop('dummy', 1)\n",
      "    return videos_matrix\n",
      "\n",
      "def feature_similarity(videos_matrix):\n",
      "    \"\"\" Calculating feature similarity for each pair of movies.\n",
      "        >>> videos_matrix = feature_similarity(videos_matrix)\n",
      "        >>> videos_matrix[:3]\n",
      "          video_id_left                                       user_id_left  \\\n",
      "        0         TV001  189500_2 328741_2 579541_2 153183_2 151295_3 3...\n",
      "        1         TV001  189500_2 328741_2 579541_2 153183_2 151295_3 3...\n",
      "        2         TV001  189500_2 328741_2 579541_2 153183_2 151295_3 3...\n",
      "\n",
      "          video_id_right                                      user_id_right  \\\n",
      "        0          TV001  189500_2 328741_2 579541_2 153183_2 151295_3 3...\n",
      "        1          TV002                                           353674_3\n",
      "        2          TV003  759744_1 379687_3 160301_1 159490_1 151124_1 1...\n",
      "\n",
      "           sim_country  sim_language  sim_adult  sim_content_owner_id  sim_broadcast  \\\n",
      "        0            1             1          1                     1              0\n",
      "        1            1             1          1                     0              0\n",
      "        2            0             0          1                     0              0\n",
      "\n",
      "           sim_season  sim_episode_count  sim_genres  sim_cast\n",
      "        0           0           1.000000           0         0\n",
      "        1           0           0.500000           0         0\n",
      "        2           0           0.064935           0         0\n",
      "    \"\"\"\n",
      "    # Country Similarity\n",
      "    def sim_country(row):\n",
      "        return (1 if row['origin_country_left'] == row['origin_country_right'] else 0)\n",
      "    videos_matrix['sim_country'] = videos_matrix.apply(sim_country, axis=1)\n",
      "    # Language similarity:\n",
      "    def sim_language(row):\n",
      "        return (1 if row['origin_language_left'] == row['origin_language_right'] else 0)\n",
      "    videos_matrix['sim_language'] = videos_matrix.apply(sim_language, axis=1)\n",
      "    # Adult similarity:\n",
      "    def sim_adult(row):\n",
      "        return (1 if row['adult_left'] == row['adult_right'] else 0)\n",
      "    videos_matrix['sim_adult'] = videos_matrix.apply(sim_adult, axis=1)\n",
      "    # Content_owner_id similarity: 0/1\n",
      "    def sim_content_owner_id(row):\n",
      "        return (1 if row['content_owner_id_left'] == row['content_owner_id_right'] else 0)\n",
      "    videos_matrix['sim_content_owner_id'] = videos_matrix.apply(sim_content_owner_id, axis=1)\n",
      "    # Broadcast_from, broadcast_to # date similarity\n",
      "    def sim_broadcast(row):\n",
      "        try:\n",
      "            bfl_date = datetime.datetime.strptime(row['broadcast_from_left'], \"%Y-%m\").date()\n",
      "            bfr_date = datetime.datetime.strptime(row['broadcast_from_right'], \"%Y-%m\").date()\n",
      "            btl_date = datetime.datetime.strptime(row['broadcast_to_left'], \"%Y-%m\").date()\n",
      "            btr_date = datetime.datetime.strptime(row['broadcast_to_right'], \"%Y-%m\").date()\n",
      "            return 1 / (abs((bfl_date-bfr_date).days) + abs((btl_date-btr_date).days))\n",
      "        except:\n",
      "            return 0\n",
      "    videos_matrix['sim_broadcast'] = videos_matrix.apply(sim_broadcast, axis=1)\n",
      "    # Season_number\n",
      "    def sim_season(row):\n",
      "        try:\n",
      "            left = int(row['season_number_left'] if row['season_number_left'].isdigit() else 0)\n",
      "            right = int(row['season_number_right'] if row['season_number_right'].isdigit() else 0)\n",
      "            return min(left,right)/max(left,right)\n",
      "        except:\n",
      "            return 0\n",
      "    videos_matrix['sim_season'] = videos_matrix.apply(sim_season, axis=1)\n",
      "    # Episode_count\n",
      "    def sim_episode_count(row):\n",
      "        try:\n",
      "            return min(row['episode_count_left'],row['episode_count_right'])/max(row['episode_count_left'],row['episode_count_right'])\n",
      "        except:\n",
      "            return 0\n",
      "    videos_matrix['sim_episode_count'] = videos_matrix.apply(sim_episode_count, axis=1)\n",
      "    # Genres\n",
      "    def sim_genres(row):\n",
      "        try:\n",
      "            left = set(re.findall(\"\\(*.g\\)\", row['genres_left']))\n",
      "            right = set(re.findall(\"\\(*.g\\)\", row['genres_right']))\n",
      "            return len(left&right) / len(left|right)\n",
      "        except:\n",
      "            return 0\n",
      "    videos_matrix['sim_genres'] = videos_matrix.apply(sim_genres, axis=1)\n",
      "    # Casts\n",
      "    def sim_cast(row):\n",
      "        try:\n",
      "            left = set(row['person_id_left'].split())\n",
      "            right = set(row['person_id_right'].split())\n",
      "            return len(left&right) / len(left|right)\n",
      "        except:\n",
      "            return 0\n",
      "    videos_matrix['sim_cast'] = videos_matrix.apply(sim_cast, axis=1)\n",
      "    return videos_matrix.drop(['container_id_left', 'origin_country_left', 'origin_language_left', 'adult_left',\n",
      "     'broadcast_from_left', 'broadcast_to_left', 'season_number_left', 'content_owner_id_left', 'genres_left',\n",
      "     'episode_count_left', 'person_id_left', 'container_id_right',\n",
      "     'origin_country_right', 'origin_language_right', 'adult_right', 'broadcast_from_right',\n",
      "     'broadcast_to_right', 'season_number_right', 'content_owner_id_right', 'genres_right',\n",
      "     'episode_count_right', 'person_id_right'],1)\n",
      "\n",
      "def jaccard_similarity(videos_matrix):\n",
      "    \"\"\" Calculating jaccard similarity for each pair of movies.\n",
      "        >>> videos_matrix = jaccard_similarity(videos_matrix)\n",
      "        >>> videos_matrix[:3]\n",
      "          video_id_left                                       user_id_left  \\\n",
      "        0         TV001  189500_2 328741_2 579541_2 153183_2 151295_3 3...\n",
      "        1         TV001  189500_2 328741_2 579541_2 153183_2 151295_3 3...\n",
      "        2         TV001  189500_2 328741_2 579541_2 153183_2 151295_3 3...\n",
      "\n",
      "          video_id_right                                      user_id_right  \\\n",
      "        0          TV001  189500_2 328741_2 579541_2 153183_2 151295_3 3...\n",
      "        1          TV002                                           353674_3\n",
      "        2          TV003  759744_1 379687_3 160301_1 159490_1 151124_1 1...\n",
      "\n",
      "           sim_country  sim_language  sim_adult  sim_content_owner_id  sim_broadcast  \\\n",
      "        0            1             1          1                     1              0\n",
      "        1            1             1          1                     0              0\n",
      "        2            0             0          1                     0              0\n",
      "\n",
      "           sim_season  sim_episode_count  sim_genres  sim_cast  jaccard_1_3  \\\n",
      "        0           0           1.000000           0         0            0\n",
      "        1           0           0.500000           0         0            0\n",
      "        2           0           0.064935           0         0            0\n",
      "\n",
      "           jaccard_2_3  jaccard_3_3\n",
      "        0            0      1.00000\n",
      "        1            0      0.00000\n",
      "        2            0      0.00159\n",
      "    \"\"\"\n",
      "    print \"Calculating Jaccard indexes for high scores - \" + str(datetime.datetime.now())\n",
      "    def jaccard_high(row): # people who like or kind of like LEFT and like RIGHT\n",
      "        try:\n",
      "            left_23 = set([item for item in row['user_id_left'].split() if not item.endswith('_1')])\n",
      "            right_23 = set([item for item in row['user_id_right'].split() if not item.endswith('_1')])\n",
      "            if len(left_23|right_23) < 1000:\n",
      "                return 0\n",
      "            else:\n",
      "                return len(left_23&right_23) / len(left_23|right_23)\n",
      "        except:\n",
      "            return 0\n",
      "    videos_matrix['jaccard_high'] = videos_matrix.apply(jaccard_high, axis=1)\n",
      "    print \"Calculating Jaccard indexes #1-3 - \" + str(datetime.datetime.now())\n",
      "    def jaccard_1_3(row): # people who do not like LEFT but like RIGHT\n",
      "        try:\n",
      "            left_1 = set([item for item in row['user_id_left'].split() if item.endswith('_1')])\n",
      "            right_3 = set([item for item in row['user_id_right'].split() if item.endswith('_3')])\n",
      "            if len(left_1|right_3) < 1000:\n",
      "                return 0\n",
      "            else:\n",
      "                return len(left_1&right_3) / len(left_1|right_3)\n",
      "        except:\n",
      "            return 0\n",
      "    videos_matrix['jaccard_1_3'] = videos_matrix.apply(jaccard_1_3, axis=1)\n",
      "    print \"Calculating Jaccard indexes #2-3 - \" + str(datetime.datetime.now())\n",
      "    def jaccard_2_3(row): # people who kind of like LEFT and like RIGHT\n",
      "        try:\n",
      "            left_2 = set([item for item in row['user_id_left'].split() if item.endswith('_2')])\n",
      "            right_3 = set([item for item in row['user_id_right'].split() if item.endswith('_3')])\n",
      "            if len(left_2|right_3) < 1000:\n",
      "                return 0\n",
      "            else:\n",
      "                return len(left_2&right_3) / len(left_2|right_3)\n",
      "        except:\n",
      "            return 0\n",
      "    videos_matrix['jaccard_2_3'] = videos_matrix.apply(jaccard_2_3, axis=1)\n",
      "    print \"Calculating Jaccard indexes #3-3 - \" + str(datetime.datetime.now())\n",
      "    def jaccard_3_3(row): # people who like LEFT and like RIGHT\n",
      "        try:\n",
      "            left_3 = set([item for item in row['user_id_left'].split() if item.endswith('_3')])\n",
      "            right_3 = set([item for item in row['user_id_right'].split() if item.endswith('_3')])\n",
      "            if len(left_3|right_3) < 1000:\n",
      "                return 0\n",
      "            else:\n",
      "                return len(left_3&right_3) / len(left_3|right_3)\n",
      "        except:\n",
      "            return 0\n",
      "    videos_matrix['jaccard_3_3'] = videos_matrix.apply(jaccard_3_3, axis=1)\n",
      "    return videos_matrix.drop(['user_id_left','user_id_right'],1)\n",
      "\n",
      "def cos_similarity(videos_matrix): # based on mv_ratio\n",
      "    behaviors = pd.read_csv('./data/20150701094451-Behavior_training.csv')\n",
      "    # user - video matrix\n",
      "    behaviors_wide = pd.pivot_table(behaviors, values=[\"mv_ratio\"],\n",
      "                             index=[\"video_id\", \"user_id\"],\n",
      "                             aggfunc=np.mean).unstack()\n",
      "    # any cells that are missing data (i.e. a user didn't buy a particular product)\n",
      "    # we're going to set to 0\n",
      "    behaviors_wide = behaviors_wide.fillna(0)\n",
      "    # this is the key. we're going to use cosine_similarity from scikit-learn\n",
      "    # to compute the distance between all beers\n",
      "    cosine_video_matrix = cosine_similarity(behaviors_wide)\n",
      "    # stuff the distance matrix into a dataframe so it's easier to operate on\n",
      "    cosine_video_matrix = pd.DataFrame(cosine_video_matrix, columns=behaviors_wide.index)\n",
      "    # give the indicies (equivalent to rownames in R) the name of the product id\n",
      "    cosine_video_matrix.index = cosine_video_matrix.columns\n",
      "    def sim_cosine_mv_ratio(row):\n",
      "        try:\n",
      "            return cosine_video_matrix[row['video_id_left']][row['video_id_right']]\n",
      "        except: # no data for row['video_id_left']\n",
      "            return 0\n",
      "    videos_matrix['sim_cosine_mv_ratio'] = videos_matrix.apply(sim_cosine_mv_ratio, axis=1)\n",
      "    return videos_matrix\n",
      "\n",
      "def output_videos_matrix_to_csv(videos_matrix):\n",
      "    videos_matrix.to_csv(\"./data/videos_similarity_matrix.csv\", encoding='utf-8', index=False)\n",
      "\n",
      "def main():\n",
      "    print \"=> Processing data - \" + str(datetime.datetime.now())\n",
      "    videos_matrix = read_data()\n",
      "    print \"=> Calculating feature similarities - \" + str(datetime.datetime.now())\n",
      "    videos_matrix = feature_similarity(videos_matrix)\n",
      "    print \"=> Calculating cosine similarities - \" + str(datetime.datetime.now())\n",
      "    videos_matrix = cos_similarity(videos_matrix)\n",
      "    print \"=> Calculating jaccard similarities - \" + str(datetime.datetime.now())\n",
      "    videos_matrix = jaccard_similarity(videos_matrix)\n",
      "    print \"=> Output to csv - \" + str(datetime.datetime.now())\n",
      "    output_videos_matrix_to_csv(videos_matrix)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "behaviors = pd.read_csv('./data/20150701094451-Behavior_training.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "behaviors = behaviors.drop('date_hour',axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.neighbors import NearestNeighbors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "behaviors_wide = pd.pivot_table(behaviors, values=[\"mv_ratio\"],\n",
      "                             index=[\"user_id\", \"video_id\"],\n",
      "                             aggfunc=np.mean).unstack()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "behaviors_wide = behaviors_wide.fillna(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "behaviors_wide.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       ..., \n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "str(datetime.datetime.now())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "'2015-08-25 15:13:06.499327'"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nbrs = NearestNeighbors(n_neighbors=10, algorithm='ball_tree').fit(behaviors_wide.values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "str(datetime.datetime.now())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nbrs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(behaviors_wide.values[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "753272"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nbrs.kneighbors(behaviors_wide.values[0], 2, return_distance=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "array([[  0, 311]])"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn.neighbors import NearestNeighbors\n",
      "samples = [[0, 0, 5], [5, 0, 0], [0, 0, 1]]\n",
      "neigh = NearestNeighbors(2, 0.4)\n",
      "neigh.fit(samples)  \n",
      "neigh.kneighbors([[1, 0, 1.3]], 1, return_distance=False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "array([[2]])"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from annoy import AnnoyIndex\n",
      "\n",
      "a = AnnoyIndex(753272 )\n",
      "\n",
      "# a.add_item(0, [1, 0, 0])\n",
      "# a.add_item(1, [0, 1, 0])\n",
      "# a.add_item(2, [0, 0, 1])\n",
      "# a.build(-1)\n",
      "# a.save('test.tree')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "behaviors = pd.read_csv('./data/20150701094451-Behavior_training.csv')\n",
      "# user - video matrix\n",
      "behaviors_wide = pd.pivot_table(behaviors, values=[\"score\"],\n",
      "                         index=[\"user_id\",\"video_id\"],\n",
      "                         aggfunc=np.mean).unstack()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# any cells that are missing data (i.e. a user didn't buy a particular product)\n",
      "# we're going to set to 0\n",
      "behaviors_wide = behaviors_wide.fillna(0)\n",
      "# this is the key. we're going to use cosine_similarity from scikit-learn\n",
      "# to compute the distance between all beers\n",
      "cosine_video_matrix = cosine_similarity(behaviors_wide)\n",
      "# stuff the distance matrix into a dataframe so it's easier to operate on\n",
      "cosine_video_matrix = pd.DataFrame(cosine_video_matrix, columns=behaviors_wide.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}